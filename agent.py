import os
import streamlit as st
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain.chat_models import init_chat_model
from dotenv import load_dotenv
load_dotenv(override=True)

# 5. Agentå¯¹è¯é“¾ + å·¥å…·è°ƒç”¨ï¼ˆæ ¸å¿ƒRAGï¼‰
DeepSeek_API_KEY = os.environ.get("DEEPSEEK_API_KEY")

def get_conversational_chain(tools, ques):
    llm = init_chat_model("deepseek-chat", model_provider="deepseek")
    prompt = ChatPromptTemplate.from_messages([
        (
            "system", 
            """ä½ æ˜¯AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œç¡®ä¿æä¾›æ‰€æœ‰ç»†èŠ‚ï¼Œå¦‚æœç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œè¯·è¯´"ç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­"ï¼Œä¸è¦æä¾›é”™è¯¯çš„ç­”æ¡ˆ"""
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])

    tool = [tools]
    agent = create_tool_calling_agent(llm, tool, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tool, verbose=True)

    response = agent_executor.invoke({"input": ques})
    print(response)
    st.write("ğŸ¤– å›ç­”: ", response['output'])